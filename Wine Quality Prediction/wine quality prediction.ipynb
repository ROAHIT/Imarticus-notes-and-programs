{"cells":[{"cell_type":"markdown","metadata":{"id":"dm7sZMi-yKNl"},"source":["  <tr>\n","        <td width=\"15%\">\n","        </td>\n","        <td>\n","            <div align=\"left\">\n","                <font size=25px>\n","                    <b>  Solution to Random Forest Classification Problem\n","                    </b>\n","                </font>\n","            </div>\n","        </td>\n","    </tr>"]},{"cell_type":"markdown","metadata":{"id":"9-LMz9MbyKNt"},"source":["## Problem Statement:\n","The objective of the dataset is to predict the quality of wine, whether it is a good quality of wine or ordinary quality \n","\n","The data set contains several parameters which are considered important while determining the quality of a wine\n","\n","The dataset consists of several predictor variables and one target variable, Quality. The target variable has values ranging from 0 to 10, the value is the rating given to each wine on a 10 point scale"]},{"cell_type":"markdown","metadata":{"id":"wtcqhBUHyKNu"},"source":["## Data Definition:\n"," \n","The real-valued features are as follows:\n","\n","1) **Fixed acidity:** acidity in the wine <br>\n","2) **Volatile acidity:** steam distillable acid in wine<br>\n","3) **Citric acid:** amount of citric acid present in wine<br>\n","4) **Residual sugar:** sugar from grapes that's left over fermentation<br>\n","5) **Chlorides:** amount of chloride in wine which gives a salty flavor<br>\n","6) **Free sulfur dioxide:** amount of sulphur dioxide which is not bound to other molecules<br>\n","7) **Total sulfur dioxide:** free sulphur dioxide plus amount of sulphur dioxide which is bounded to other molecules\n","8) **Density:** molecular density of wine<br>\n","9) **Ph:** pH value of wines<br>\n","10) **Sulphates:** amount of sulphur added to prevent oxidation of wine and bacterial spoilage<br>\n","11) **Alcohol:** amount of alcohol <br>\n","\n","Output variable (desired target):\n","\n","11) **Quality** - values ranging from 0 to 10, which gives the rating of each wine"]},{"cell_type":"markdown","metadata":{"id":"mNOVkPbgyKNv"},"source":["## Content\n","\n","1. **[Import Libraries](#import_lib)**\n","2. **[Exploratory Data Analysis](#exploratory)**\n","3. **[Building a RF model](#model)**"]},{"cell_type":"markdown","metadata":{"id":"zipcjFHryKNv"},"source":["<a id='import_lib'></a>\n","## 1. Import Libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vOT_McBPyKNw"},"outputs":[],"source":["# Numpy library is used to work with arrays and also has functions for working in domain of linear algebra\n","import numpy as np\n","\n","# Pandas library provides easy to use data structures and data analysis tools\n","import pandas as pd\n","\n","# Matplotlib library is used for plotting graphs \n","import matplotlib.pyplot as plt\n","\n","# Seaborn library is used for generating visualizations and is based on matplotlib\n","import seaborn as sns\n","\n","# Sklearn pre-processing package provides several common utility functions and transformer classes for standardization of data\n","from sklearn import preprocessing\n","pd.set_option('display.float_format', lambda x: '%.2f' % x)\n","\n","# Importing the library to split the data into train and test set\n","from sklearn.model_selection import train_test_split\n","\n","# Importing the evaluation metric accuracy score of the model\n","from sklearn.metrics import accuracy_score\n","\n","# Importing the evaluation metric confusion matrix \n","from sklearn.metrics import confusion_matrix\n","\n","# Importing the random forets classifier\n","from sklearn.ensemble import RandomForestClassifier\n","\n","# Import roc_curve to compute Receiver Operating Characteristics \n","from sklearn.metrics import roc_curve\n","\n","# Import roc_auc_score to calculate the area uner the curve\n","from sklearn.metrics import roc_auc_score\n","\n","# pyplot is a state-based interface to matplotlib which provides a MATLAB-like way of plotting.\n","from matplotlib import pyplot"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"o3ryl2cyyN-6"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B2gPvtOEyKNy"},"outputs":[],"source":["# Let us read the data\n","wine = pd.read_csv('/content/drive/MyDrive/0.MKCE/5.Random Forest/3 Take-Home Assignment/wine.csv')"]},{"cell_type":"markdown","metadata":{"id":"1653FF8PyKNz"},"source":["<a id='exploratory'></a>\n","## 2. Exploratory Data Analysis (EDA)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S4ImlPiFyKN0"},"outputs":[],"source":["# Ques 1 a) Visualizing the first 10 rows from the data set\n","wine.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7iNQ_iapyKN1"},"outputs":[],"source":["# Let us take a look at the data types of the variables\n","wine.dtypes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VKUxHDXCyKN1"},"outputs":[],"source":["# Ques 1 b) Check the shape of the data set\n","wine.shape"]},{"cell_type":"markdown","metadata":{"id":"2ZP0l45NyKN2"},"source":["We can see here that the data set contains 1599 observations and 12 attributes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PD7awiquyKN2"},"outputs":[],"source":["# Ques 1 c) Show distribution of the numerical columns\n","sns.set()\n","fig = plt.figure(figsize = [15, 15])\n","\n","# Specifying the columns\n","cols = ['fixed acidity', 'volatile acidity', 'citric acid', \n","        'residual sugar', 'chlorides', 'free sulfur dioxide', \n","        'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol', 'quality']\n","count = 1\n","\n","# Generating the plots\n","for col in cols :\n","    plt.subplot(4,3,count)\n","    sns.distplot(wine[col],hist_kws = dict(edgecolor = \"k\", linewidth = 1,color = 'grey'), color = 'red')\n","    count+=1\n","plt.show() "]},{"cell_type":"markdown","metadata":{"id":"8iWCXEotyKN3"},"source":["Here we can see the distribution of all the attributes, including the target variable"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IqKpvPqIyKN3"},"outputs":[],"source":["# Ques 1 d) Generate the correlation matrix\n","plt.figure(figsize = (8, 8))\n","sns.heatmap(wine.corr(), annot=True, linewidths=0.05, fmt= '.2f',cmap=\"magma\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"OmnRXob8yKN3"},"source":["A high positive correlation of 0.67 is observed between :\n","\n","fixed acidity & citric acid<br>\n","fixed acidity & density<br>\n","free sulfur dioxide & total sulfur dioxide<br>\n","fixed acidity & pH are negatively correlated with a high absolute magnitude of 0.68 ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8H6ua9qJyKN4"},"outputs":[],"source":["# Ques 1 e) Visualize whether any attributes are related to the target variable\n","sns.set_style(\"whitegrid\")\n","fig = plt.figure(figsize = [15, 15])\n","\n","# Plotting the independent variables with the target variable\n","cols = ['fixed acidity', 'volatile acidity', 'citric acid', \n","        'residual sugar', 'chlorides', 'free sulfur dioxide', \n","        'total sulfur dioxide', 'density', 'pH', 'sulphates', 'alcohol']\n","count = 1\n","\n","# Generating the plots\n","for col in cols :\n","    plt.subplot(4,3,count)\n","    sns.barplot(data = wine, x = 'quality', y = col)\n","    count+=1\n","plt.show()  "]},{"cell_type":"markdown","metadata":{"id":"CSVCt8EOyKN4"},"source":["Here, we can see that:\n","There is an increase in the following attributes as the wine quality increases :\n","\n","1) citric acid <br>\n","2) sulphates<br>\n","3) alcohol<br>\n","\n","A decrease is observed in the following as the wine quality increases :\n","\n","1) volatile acidity<br>\n","2) chlorides<br>\n","3) pH<br>"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z7BXw5JNyKN4"},"outputs":[],"source":["# Ques 2) Generate pair-plot for the data\n","sns.pairplot(wine, hue = 'quality')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"qR5a1evMyKN5"},"source":["Here we can see the histogram for each variable as well as the scatter plots based on the quality of wines"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CLEVybgoyKN5"},"outputs":[],"source":["# Ques 3) Generate a count plot for the target variable (quality)\n","sns.countplot(data = wine, x = 'quality')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"tBn51qFUyKN5"},"source":["Here we can see that most of the wines have the quality rating of 5 or 6"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"db28FKSqyKN6"},"outputs":[],"source":["# Ques 4) Converting the target variable 'Quality' to categorical\n","# Such that \n","# Wines having the “Quality” value > 6.5  are assigned value 1, and \n","# Wines having the “Quality” value < 6.5, are assigned value 0\n","# Where 0: Ordinary Quality of wine and 1: High quality of wine\n","\n","wine['quality'] = wine.quality.apply(lambda x : 1 if x > 6.5 else 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8d72Pcl7yKN6"},"outputs":[],"source":["# Let us again visualize the count plot for the target variable\n","sns.countplot(data = wine, x = 'quality')\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"8u-gY7boyKN7"},"source":["We can see that very few wines in the data set are of high quality while most of them are of ordinary quality"]},{"cell_type":"markdown","metadata":{"id":"mzkjIXrtyKN7"},"source":["<a id='model'></a>\n","## 3. Building a RF model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GK10R59yKN7"},"outputs":[],"source":["# Splitting the data set into train and test sets\n","x = wine.drop('quality',1)\n","y = wine['quality']\n","\n","x_train, x_test, y_train, y_test = train_test_split(x, y, train_size = 0.8, random_state = 100)"]},{"cell_type":"markdown","metadata":{"id":"VaWD3DfwyKN8"},"source":["### Parameters in the classifier\n","1) **n_estimators:** number of trees in the forest<br>\n","2) **criterion:** the function to measure the quality of a split. Supported criteria are “gini” for the Gini impurity and “entropy” for the information gain<br>\n","3) **min_samples_split:** the minimum number of samples required to split an internal node, default = 2<br>\n","4) **min_samples_leaf:** the minimum number of samples required to be at a leaf node<br>\n","5) **max_features:** the number of features to consider when looking for the best split, default = \"auto\" <br>\n","6) **random_state:** controls both the randomness of the bootstrapping of the samples used when building trees and the sampling of the features to consider when looking for the best split at each node<br>\n","7) **max_depth:** the maximum depth of the tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Tz7z0BKeyKN8"},"outputs":[],"source":["# Ques 5) Build a random forest classifier\n","# Creating a random forest classifier\n","clf_rf = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', \n","                                min_samples_split = 10, min_samples_leaf = 9, max_features = \"auto\",\n","                                random_state = 500, max_depth = 12) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1QvOY7ouyKN8"},"outputs":[],"source":["# Training the model \n","clf_fit = clf_rf.fit(x_train, y_train) \n","\n","# Predicting the quality\n","y_pred = clf_fit.predict(x_test) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xHNmv4IwyKN8"},"outputs":[],"source":["# Checking the accuracy of the model\n","accuracy_score(y_test, y_pred)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"m4WC_eC0yKN9"},"outputs":[],"source":["# Predicting the probabilities of wine being of high quality\n","y_proba = clf_fit.predict_proba(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SAh3taPbyKN9"},"outputs":[],"source":["# Visualizing the confusion matrix\n","print(confusion_matrix(y_test, y_pred))"]},{"cell_type":"markdown","metadata":{"id":"kg14b5QQyKN9"},"source":["We can see that our model is able to classify the wine quality with an accuracy of 90% and in the confusion matrix we can see that there are very few values which are being wrongly classified. Let us now take a look at the AUC for the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mDVq1ZDryKN-"},"outputs":[],"source":["# Visualizing the ROC-AUC curve \n","\n","# We take the predicted values of class 1\n","y_predicted = y_proba[:,1]\n","\n","# We check to see if the right values have been considered from the predicted values\n","print(y_predicted)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xS_YKqSCyKN-"},"outputs":[],"source":["# Using roc_curve() to generate fpr & tpr values\n","fpr, tpr, thresholds = roc_curve(y_test,y_predicted)\n","\n","# Passing the fpr & tpr values to auc() to calculate the area under curve\n","from sklearn.metrics import auc\n","roc_auc = auc(fpr,tpr)\n","print(\"Area under the curve for first model\",roc_auc)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6d9OcrI2yKN-"},"outputs":[],"source":["# Plotting the ROC curve\n","plt.figure()\n","plt.plot(fpr, tpr, color = 'orange', lw = 2, label = 'ROC curve (area under curve =%0.2f)'%roc_auc)\n","\n","plt.plot([0,1],[0,1], color = 'darkgrey',lw = 2,linestyle='--')\n","plt.xlim([0.0,1.0])\n","plt.ylim([0.0,1.0])\n","plt.xlabel('False Positive Rate (1-Specificity)')\n","plt.ylabel('True Positive Rate (Sensitivity)')\n","plt.title('ROC Curve for first model')\n","plt.legend(loc = \"upper left\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"AAesmrs9yKN-"},"source":["So the AUC is 0.88 which is considered good for a model"]},{"cell_type":"markdown","metadata":{"id":"mKHI_K-ryKN_"},"source":["### Perform Hyperparameter Tuning"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zcI_h8CVyKN_"},"outputs":[],"source":["# Again creating a random forest classifier\n","clf_rf2 = RandomForestClassifier(n_estimators = 100, criterion = 'gini', \n","                                min_samples_split = 2, min_samples_leaf = 5, max_features = \"auto\",\n","                                random_state = 100, max_depth = 3) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K6d_lqt1yKN_"},"outputs":[],"source":["# Training the model \n","clf_fit_2 = clf_rf2.fit(x_train, y_train) \n","\n","# Predicting the quality \n","y_pred_2 = clf_fit_2.predict(x_test) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wXuRJiahyKN_"},"outputs":[],"source":["# Checking the accuracy of the model\n","from sklearn.metrics import accuracy_score\n","accuracy_score(y_test, y_pred_2)"]},{"cell_type":"markdown","metadata":{"id":"49woeBILyKOA"},"source":["We can see here that by changing the values of the parameter, there is a slight increase in the accuracy. Though the increase is not significant as the value only improved by 0.3, in the first model accuracy was 90.3 and now the accuracy is 90.6. Earlier we were using 'Entropy' as criterion, now we are using 'Gini' as criterion, the max depth of the tree has been decreased and so on. Similarly, we can keep on tuning the parameters, to obtain the highest accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0SAmsMUcyKOA"},"outputs":[],"source":["# Predicting the probabilities of wine being of high quality using the second model\n","y_proba_2 = clf_fit.predict_proba(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_Xk2KaCvyKOA"},"outputs":[],"source":["# Visualizing the ROC-AUC curve \n","\n","# We take the predicted values of class 1\n","y_predicted_2 = y_proba_2[:,1]\n","\n","# Using roc_curve() to generate fpr & tpr values\n","fpr, tpr, thresholds = roc_curve(y_test, y_predicted_2)\n","\n","# Passing the fpr & tpr values to auc() to calculate the area under curve\n","from sklearn.metrics import auc\n","roc_auc = auc(fpr,tpr)\n","print(\"Area under the curve for the second model\",roc_auc)"]},{"cell_type":"markdown","metadata":{"id":"xiCOjrMuyKOB"},"source":["There is no change in the AUC value of both the models"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"Random Forest _Take Home Solution.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}